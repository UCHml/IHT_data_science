{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Selection of data.**"
      ],
      "metadata": {
        "id": "RzNa--3AUEMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing modules, defending some functions, reading the data."
      ],
      "metadata": {
        "id": "J5IEYw-qUN1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pVtOUqhdWsz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "df = pd.read_csv(\"/content/sample_data/car.data\", names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class'])\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMcBEjmnelze",
        "outputId": "850b327e-d6f0-486b-b1d4-d12e2d1840d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     buying  maint  doors persons lug_boot safety  class\n",
            "0     vhigh  vhigh      2       2    small    low  unacc\n",
            "1     vhigh  vhigh      2       2    small    med  unacc\n",
            "2     vhigh  vhigh      2       2    small   high  unacc\n",
            "3     vhigh  vhigh      2       2      med    low  unacc\n",
            "4     vhigh  vhigh      2       2      med    med  unacc\n",
            "...     ...    ...    ...     ...      ...    ...    ...\n",
            "1723    low    low  5more    more      med    med   good\n",
            "1724    low    low  5more    more      med   high  vgood\n",
            "1725    low    low  5more    more      big    low  unacc\n",
            "1726    low    low  5more    more      big    med   good\n",
            "1727    low    low  5more    more      big   high  vgood\n",
            "\n",
            "[1728 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Comments on reading. Short explanations about the need to transform and supplement data in certain columns:***\n",
        "\n",
        ">\n",
        "\n",
        "The resulting data is in tabular DataFrame  format with seven columns: '***buying***', '***maint***', '***doors***', '***persons***', '***lug_boot***', '***safety***' and '***class***'. Each row corresponds to a specific car.\n",
        "To prepare data for modeling, we can use the **Label Encoding** technique to replace categorical values with numeric ones."
      ],
      "metadata": {
        "id": "qs8syHvFUW0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Transformation of data**"
      ],
      "metadata": {
        "id": "uB3av-ujU2RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "print(df)\n",
        "\n",
        "# Split into features and target\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GoTJelqemWu",
        "outputId": "db13ac6e-f2b1-4f86-cb18-7ffb1ac4aad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      buying  maint  doors  persons  lug_boot  safety  class\n",
            "0          3      3      0        0         2       1      2\n",
            "1          3      3      0        0         2       2      2\n",
            "2          3      3      0        0         2       0      2\n",
            "3          3      3      0        0         1       1      2\n",
            "4          3      3      0        0         1       2      2\n",
            "...      ...    ...    ...      ...       ...     ...    ...\n",
            "1723       1      1      3        2         1       2      1\n",
            "1724       1      1      3        2         1       0      3\n",
            "1725       1      1      3        2         0       1      2\n",
            "1726       1      1      3        2         0       2      1\n",
            "1727       1      1      3        2         0       0      3\n",
            "\n",
            "[1728 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Comments on the conversion. Explanation of the need for standardization and normalization of data:***\n",
        "\n",
        "\n",
        "The resulting data were subjected to the **Label Encoding** process, where the categorical values of each attribute were replaced by their corresponding numerical equivalents. For example, '***buying***' has four possible categories (***v-high, high, med, low***), which are now represented by numerical values between 0 and 3. This transformation makes the data suitable for use in machine learning algorithms that require numerical input.\n",
        "\n",
        "Regarding standardization and normalization for the simple multilayer perceptron (**MLP**):\n",
        "In the case of a simple **MLP**, standardization or normalization of the data may be important because the algorithm is sensitive to the values of the input attributes and their scales.\n",
        "Standardization can improve the speed of convergence of the algorithm and avoid the disproportionate impact of large values of individual attributes."
      ],
      "metadata": {
        "id": "qnQTVhgfVCIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization of data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(X_train_scaled, X_test_scaled)\n",
        "\n",
        "# Normalization of data\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train_normalized = min_max_scaler.fit_transform(X_train_scaled)\n",
        "X_test_normalized = min_max_scaler.transform(X_test_scaled)\n",
        "\n",
        "print(X_train_normalized, X_test_normalized)\n",
        "\n",
        "# Convert to TensorFlow tensors\n",
        "X_train_tensor = tf.convert_to_tensor(X_train_normalized, dtype=tf.float32)\n",
        "y_train_tensor = tf.convert_to_tensor(y_train.values, dtype=tf.int64)\n",
        "X_test_tensor = tf.convert_to_tensor(X_test_normalized, dtype=tf.float32)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test.values, dtype=tf.int64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H3rnV6qemnW",
        "outputId": "77affad7-0d74-4ef7-ac23-821d5e2d8ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.35185249  1.34948141  1.34190571  1.22503522 -1.22474807 -1.23299669]\n",
            " [ 0.4506175   1.34948141 -0.44385615 -0.00803009  1.22120833  1.22765519]\n",
            " [-0.4506175  -0.43433811  1.34190571 -1.24109541 -1.22474807 -1.23299669]\n",
            " ...\n",
            " [-1.35185249 -0.43433811  1.34190571  1.22503522 -0.00176987 -1.23299669]\n",
            " [-0.4506175  -1.32624787  0.44902478 -1.24109541  1.22120833  1.22765519]\n",
            " [ 0.4506175   0.45757165 -0.44385615  1.22503522  1.22120833  1.22765519]] [[-1.35185249 -1.32624787  0.44902478 -1.24109541 -0.00176987 -1.23299669]\n",
            " [ 0.4506175  -0.43433811 -1.33673708 -0.00803009 -0.00176987  1.22765519]\n",
            " [-1.35185249 -1.32624787  1.34190571 -1.24109541 -1.22474807  1.22765519]\n",
            " ...\n",
            " [ 0.4506175  -0.43433811 -1.33673708  1.22503522  1.22120833 -0.00267075]\n",
            " [ 1.35185249  1.34948141  1.34190571  1.22503522  1.22120833 -1.23299669]\n",
            " [ 0.4506175   0.45757165 -1.33673708 -1.24109541 -0.00176987  1.22765519]]\n",
            "[[1.         1.         1.         1.         0.         0.        ]\n",
            " [0.66666667 1.         0.33333333 0.5        1.         1.        ]\n",
            " [0.33333333 0.33333333 1.         0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.33333333 1.         1.         0.5        0.        ]\n",
            " [0.33333333 0.         0.66666667 0.         1.         1.        ]\n",
            " [0.66666667 0.66666667 0.33333333 1.         1.         1.        ]] [[0.         0.         0.66666667 0.         0.5        0.        ]\n",
            " [0.66666667 0.33333333 0.         0.5        0.5        1.        ]\n",
            " [0.         0.         1.         0.         0.         1.        ]\n",
            " ...\n",
            " [0.66666667 0.33333333 0.         1.         1.         0.5       ]\n",
            " [1.         1.         1.         1.         1.         0.        ]\n",
            " [0.66666667 0.66666667 0.         0.         0.5        1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standardization:**\n",
        "\n",
        "'***buying***', '***maint***', '***doors***', '***persons***', '***lug_boot***', '***safety***': After **Label Encoding** we have numerical values, but their scale can vary greatly.\n",
        "Standardization allows to rescale attributes so that their values have a mean of 0 and a standard deviation of 1.\n",
        "Formula: Standardized_Value = (X - Mean(X)) / StdDev(X), where X is the original value of the attribute, Mean(X) is the average value of the attribute, StdDev(X) is the standard deviation of the attribute.\n",
        "\n",
        "**Normalization (optional):**\n",
        "\n",
        "Normalization can also be used to bring values between 0 and 1.\n",
        "Formula: Normalized_Value = (X - Min(X)) / (Max(X) - Min(X)), where X is the original value of the attribute, Min(X) is the minimum value of the attribute, and Max(X) is the maximum value of the attribute."
      ],
      "metadata": {
        "id": "rzhmaQpPVhbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Simple MLP learning**"
      ],
      "metadata": {
        "id": "F_6vq96lWelQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Theoretical description of the perceptron:***\n",
        "\n",
        "CarClassifier is a simple neural network model for the task of car classification. It consists of an input layer, a hidden layer with **ReLU** activation, and an output layer with **softmax** activation. The model is designed to process the input features of the car, such as purchase price, maintenance cost, number of doors, etc. The hidden layer introduces nonlinearity using the Rectified Linear Unit (**ReLU**) activation function and at the output we get the probabilities of belonging to one of the classes using the **softmax** function, which is usually used for multiclass classification. The output layer generates a set of scores for each class and the class with the highest score is assumed as the final output. The model is trained using the **Adam optimizer** and the cross-entropy loss function for 300 epochs, achieving accuracy on the test set of 97.11% on the car classification dataset."
      ],
      "metadata": {
        "id": "hJqAc5-pXS-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.shape[1]\n",
        "hidden_size = 64\n",
        "output_size = len(set(y))  # Number of classes\n",
        "num_epochs = 300\n",
        "\n",
        "# Define a simple neural network model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(hidden_size, activation='relu', input_shape=(input_size)),\n",
        "    layers.Dense(output_size, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Convert y_train to numpy array if it's not already\n",
        "y_train_array = y_train_tensor.numpy() if isinstance(y_train_tensor, tf.Tensor) else y_train_tensor\n",
        "\n",
        "# Training loop\n",
        "model.fit(X_train_tensor, y_train_array, epochs=num_epochs, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "predictions = model.predict(X_test_tensor)\n",
        "predicted_labels = tf.argmax(predictions, axis=1)\n",
        "accuracy = accuracy_score(y_test_tensor.numpy(), predicted_labels.numpy())\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "fsYKumG_em9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff165d36-0cd5-476a-ac61-7de0a1ce8eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "44/44 [==============================] - 2s 2ms/step - loss: 1.0918 - accuracy: 0.5897\n",
            "Epoch 2/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.8422 - accuracy: 0.7055\n",
            "Epoch 3/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.7816 - accuracy: 0.7055\n",
            "Epoch 4/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.7499 - accuracy: 0.7135\n",
            "Epoch 5/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.7283 - accuracy: 0.7142\n",
            "Epoch 6/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.7156\n",
            "Epoch 7/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.7207\n",
            "Epoch 8/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.7192\n",
            "Epoch 9/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.7236\n",
            "Epoch 10/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.7308\n",
            "Epoch 11/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.7359\n",
            "Epoch 12/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.7424\n",
            "Epoch 13/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.7467\n",
            "Epoch 14/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.7504\n",
            "Epoch 15/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.7562\n",
            "Epoch 16/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7562\n",
            "Epoch 17/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7583\n",
            "Epoch 18/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7634\n",
            "Epoch 19/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7648\n",
            "Epoch 20/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7728\n",
            "Epoch 21/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7764\n",
            "Epoch 22/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7793\n",
            "Epoch 23/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7800\n",
            "Epoch 24/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7851\n",
            "Epoch 25/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7873\n",
            "Epoch 26/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7894\n",
            "Epoch 27/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8003\n",
            "Epoch 28/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8017\n",
            "Epoch 29/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8068\n",
            "Epoch 30/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8082\n",
            "Epoch 31/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8119\n",
            "Epoch 32/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8082\n",
            "Epoch 33/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8198\n",
            "Epoch 34/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8205\n",
            "Epoch 35/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8205\n",
            "Epoch 36/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8256\n",
            "Epoch 37/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8292\n",
            "Epoch 38/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8300\n",
            "Epoch 39/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8307\n",
            "Epoch 40/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8321\n",
            "Epoch 41/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8321\n",
            "Epoch 42/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8365\n",
            "Epoch 43/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8444\n",
            "Epoch 44/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8444\n",
            "Epoch 45/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8459\n",
            "Epoch 46/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8480\n",
            "Epoch 47/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8473\n",
            "Epoch 48/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8480\n",
            "Epoch 49/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8495\n",
            "Epoch 50/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8546\n",
            "Epoch 51/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8589\n",
            "Epoch 52/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8531\n",
            "Epoch 53/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8575\n",
            "Epoch 54/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8582\n",
            "Epoch 55/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8589\n",
            "Epoch 56/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8661\n",
            "Epoch 57/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8683\n",
            "Epoch 58/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8560\n",
            "Epoch 59/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8603\n",
            "Epoch 60/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8640\n",
            "Epoch 61/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8705\n",
            "Epoch 62/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8698\n",
            "Epoch 63/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8676\n",
            "Epoch 64/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8705\n",
            "Epoch 65/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8712\n",
            "Epoch 66/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.3032 - accuracy: 0.8741\n",
            "Epoch 67/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8792\n",
            "Epoch 68/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8835\n",
            "Epoch 69/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8770\n",
            "Epoch 70/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2909 - accuracy: 0.8828\n",
            "Epoch 71/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2871 - accuracy: 0.8842\n",
            "Epoch 72/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.8864\n",
            "Epoch 73/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.8821\n",
            "Epoch 74/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8849\n",
            "Epoch 75/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.8842\n",
            "Epoch 76/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2748 - accuracy: 0.8915\n",
            "Epoch 77/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8922\n",
            "Epoch 78/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.8944\n",
            "Epoch 79/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8951\n",
            "Epoch 80/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.8965\n",
            "Epoch 81/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8980\n",
            "Epoch 82/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.8980\n",
            "Epoch 83/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.9045\n",
            "Epoch 84/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.8915\n",
            "Epoch 85/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.9009\n",
            "Epoch 86/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2524 - accuracy: 0.9030\n",
            "Epoch 87/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.9153\n",
            "Epoch 88/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.9175\n",
            "Epoch 89/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.9103\n",
            "Epoch 90/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.9139\n",
            "Epoch 91/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.9103\n",
            "Epoch 92/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2401 - accuracy: 0.9110\n",
            "Epoch 93/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9153\n",
            "Epoch 94/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2362 - accuracy: 0.9168\n",
            "Epoch 95/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.9219\n",
            "Epoch 96/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2309 - accuracy: 0.9240\n",
            "Epoch 97/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.2290 - accuracy: 0.9276\n",
            "Epoch 98/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9284\n",
            "Epoch 99/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9262\n",
            "Epoch 100/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9320\n",
            "Epoch 101/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9342\n",
            "Epoch 102/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9291\n",
            "Epoch 103/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9291\n",
            "Epoch 104/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9363\n",
            "Epoch 105/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9291\n",
            "Epoch 106/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9356\n",
            "Epoch 107/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9334\n",
            "Epoch 108/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9370\n",
            "Epoch 109/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9385\n",
            "Epoch 110/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9363\n",
            "Epoch 111/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9385\n",
            "Epoch 112/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9385\n",
            "Epoch 113/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9342\n",
            "Epoch 114/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9392\n",
            "Epoch 115/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9428\n",
            "Epoch 116/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9465\n",
            "Epoch 117/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9428\n",
            "Epoch 118/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9465\n",
            "Epoch 119/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9479\n",
            "Epoch 120/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9522\n",
            "Epoch 121/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9465\n",
            "Epoch 122/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9530\n",
            "Epoch 123/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9537\n",
            "Epoch 124/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9472\n",
            "Epoch 125/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9551\n",
            "Epoch 126/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9537\n",
            "Epoch 127/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9580\n",
            "Epoch 128/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9580\n",
            "Epoch 129/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.9566\n",
            "Epoch 130/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9559\n",
            "Epoch 131/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9595\n",
            "Epoch 132/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.9559\n",
            "Epoch 133/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9624\n",
            "Epoch 134/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9580\n",
            "Epoch 135/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9624\n",
            "Epoch 136/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9588\n",
            "Epoch 137/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9624\n",
            "Epoch 138/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9667\n",
            "Epoch 139/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9645\n",
            "Epoch 140/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1568 - accuracy: 0.9631\n",
            "Epoch 141/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9667\n",
            "Epoch 142/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.9696\n",
            "Epoch 143/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1523 - accuracy: 0.9682\n",
            "Epoch 144/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9725\n",
            "Epoch 145/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9667\n",
            "Epoch 146/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9689\n",
            "Epoch 147/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9703\n",
            "Epoch 148/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9660\n",
            "Epoch 149/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9696\n",
            "Epoch 150/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9711\n",
            "Epoch 151/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9660\n",
            "Epoch 152/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9718\n",
            "Epoch 153/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9732\n",
            "Epoch 154/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9711\n",
            "Epoch 155/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9732\n",
            "Epoch 156/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9768\n",
            "Epoch 157/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9718\n",
            "Epoch 158/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9790\n",
            "Epoch 159/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9768\n",
            "Epoch 160/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9740\n",
            "Epoch 161/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9776\n",
            "Epoch 162/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9740\n",
            "Epoch 163/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9747\n",
            "Epoch 164/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9768\n",
            "Epoch 165/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9768\n",
            "Epoch 166/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9776\n",
            "Epoch 167/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9790\n",
            "Epoch 168/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9783\n",
            "Epoch 169/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1228 - accuracy: 0.9783\n",
            "Epoch 170/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9768\n",
            "Epoch 171/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9797\n",
            "Epoch 172/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9797\n",
            "Epoch 173/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9797\n",
            "Epoch 174/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9790\n",
            "Epoch 175/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9812\n",
            "Epoch 176/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9812\n",
            "Epoch 177/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9841\n",
            "Epoch 178/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9826\n",
            "Epoch 179/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9834\n",
            "Epoch 180/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9834\n",
            "Epoch 181/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9805\n",
            "Epoch 182/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.9826\n",
            "Epoch 183/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.9819\n",
            "Epoch 184/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9819\n",
            "Epoch 185/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9797\n",
            "Epoch 186/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9812\n",
            "Epoch 187/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9834\n",
            "Epoch 188/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9812\n",
            "Epoch 189/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9826\n",
            "Epoch 190/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9841\n",
            "Epoch 191/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9834\n",
            "Epoch 192/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9834\n",
            "Epoch 193/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9855\n",
            "Epoch 194/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9848\n",
            "Epoch 195/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9848\n",
            "Epoch 196/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9841\n",
            "Epoch 197/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9834\n",
            "Epoch 198/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9877\n",
            "Epoch 199/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9848\n",
            "Epoch 200/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.9834\n",
            "Epoch 201/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9877\n",
            "Epoch 202/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0974 - accuracy: 0.9863\n",
            "Epoch 203/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9855\n",
            "Epoch 204/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0955 - accuracy: 0.9877\n",
            "Epoch 205/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9826\n",
            "Epoch 206/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0945 - accuracy: 0.9870\n",
            "Epoch 207/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0937 - accuracy: 0.9863\n",
            "Epoch 208/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0945 - accuracy: 0.9863\n",
            "Epoch 209/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9870\n",
            "Epoch 210/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9877\n",
            "Epoch 211/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9870\n",
            "Epoch 212/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9884\n",
            "Epoch 213/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9863\n",
            "Epoch 214/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9877\n",
            "Epoch 215/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9870\n",
            "Epoch 216/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9899\n",
            "Epoch 217/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9884\n",
            "Epoch 218/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9906\n",
            "Epoch 219/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9855\n",
            "Epoch 220/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9826\n",
            "Epoch 221/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9899\n",
            "Epoch 222/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9884\n",
            "Epoch 223/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.9877\n",
            "Epoch 224/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.9884\n",
            "Epoch 225/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9855\n",
            "Epoch 226/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9891\n",
            "Epoch 227/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9891\n",
            "Epoch 228/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9891\n",
            "Epoch 229/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9891\n",
            "Epoch 230/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9906\n",
            "Epoch 231/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9877\n",
            "Epoch 232/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9884\n",
            "Epoch 233/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.9891\n",
            "Epoch 234/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9891\n",
            "Epoch 235/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9906\n",
            "Epoch 236/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9877\n",
            "Epoch 237/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9899\n",
            "Epoch 238/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9884\n",
            "Epoch 239/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9906\n",
            "Epoch 240/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9906\n",
            "Epoch 241/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9899\n",
            "Epoch 242/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9906\n",
            "Epoch 243/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9920\n",
            "Epoch 244/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9899\n",
            "Epoch 245/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9913\n",
            "Epoch 246/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9899\n",
            "Epoch 247/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9899\n",
            "Epoch 248/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9877\n",
            "Epoch 249/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9913\n",
            "Epoch 250/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9906\n",
            "Epoch 251/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9913\n",
            "Epoch 252/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9906\n",
            "Epoch 253/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9899\n",
            "Epoch 254/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9928\n",
            "Epoch 255/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9942\n",
            "Epoch 256/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9920\n",
            "Epoch 257/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9920\n",
            "Epoch 258/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9928\n",
            "Epoch 259/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9935\n",
            "Epoch 260/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9906\n",
            "Epoch 261/300\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9906\n",
            "Epoch 262/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9928\n",
            "Epoch 263/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9928\n",
            "Epoch 264/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9920\n",
            "Epoch 265/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9935\n",
            "Epoch 266/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9942\n",
            "Epoch 267/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9913\n",
            "Epoch 268/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9920\n",
            "Epoch 269/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9935\n",
            "Epoch 270/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9906\n",
            "Epoch 271/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9935\n",
            "Epoch 272/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9906\n",
            "Epoch 273/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9935\n",
            "Epoch 274/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9913\n",
            "Epoch 275/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9935\n",
            "Epoch 276/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9957\n",
            "Epoch 277/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9913\n",
            "Epoch 278/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9942\n",
            "Epoch 279/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9920\n",
            "Epoch 280/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9935\n",
            "Epoch 281/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9928\n",
            "Epoch 282/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9949\n",
            "Epoch 283/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9957\n",
            "Epoch 284/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9928\n",
            "Epoch 285/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9928\n",
            "Epoch 286/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9942\n",
            "Epoch 287/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9928\n",
            "Epoch 288/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9928\n",
            "Epoch 289/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9935\n",
            "Epoch 290/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9957\n",
            "Epoch 291/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9942\n",
            "Epoch 292/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9957\n",
            "Epoch 293/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9935\n",
            "Epoch 294/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9913\n",
            "Epoch 295/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9949\n",
            "Epoch 296/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9935\n",
            "Epoch 297/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9942\n",
            "Epoch 298/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9928\n",
            "Epoch 299/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9949\n",
            "Epoch 300/300\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9949\n",
            "11/11 [==============================] - 0s 2ms/step\n",
            "Test Accuracy: 98.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Comments on the results of learning a perceptrone. Model quality analysis:***\n",
        "\n",
        "This code uses a simple neural network to classify cars based on given characteristics. The model has one hidden layer with **ReLU** activation and an output layer with a **softmax** activation function to obtain probabilities for different classes. The categorical loss of the **cross-entropy** function is used to train the model, the optimizer is **Adam**. The training duration is limited to 1000 epochs. After training, the model is evaluated on the test set, and the classification accuracy is derived."
      ],
      "metadata": {
        "id": "ZeKrBAKYgVzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_tensor, predicted_labels)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Compute and display ROC-AUC score\n",
        "y_test_one_hot = tf.keras.utils.to_categorical(y_test_tensor, num_classes=output_size)\n",
        "roc_auc = roc_auc_score(y_test_one_hot, predictions)\n",
        "print(f'ROC-AUC: {roc_auc:.4f}')\n",
        "\n",
        "# Visualize the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test_one_hot.ravel(), predictions.ravel())\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, label=f'ROC-AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "uFm9oNj-h4AZ",
        "outputId": "f061159f-8e69-4b3b-be06-2de5e2db101f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 79   1   3   0]\n",
            " [  0  11   0   0]\n",
            " [  0   0 235   0]\n",
            " [  1   0   0  16]]\n",
            "ROC-AUC: 0.9987\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Construction of classification trees**"
      ],
      "metadata": {
        "id": "kgfS9fJWlzRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Discussion of possible options for selecting the target attribute. Formulas for calculating entropy and information gain for processed data. Classification tree model***"
      ],
      "metadata": {
        "id": "4f6uTvE-l55Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided dataset has a target attribute of '***class***' which represents the eligibility of the vehicle. It is a natural choice for classification tasks where the task is to predict the acceptability category of a vehicle based on its characteristics.\n",
        "\n",
        "**Entropy (H):**\n",
        "\n",
        "Formula: entropy (H) = - sum (p_i * log2(p_i)) for each class i.\n",
        "Here p_i represents a selection of instances in class i.\n",
        "\n",
        "**Information Gain (IG):**\n",
        "\n",
        "Information gain measures the effectiveness of an attribute in reducing uncertainty.\n",
        "Formula: information gain (IG) = entropy (S)  sum [(|S_v| / |S|) * entropy (S_v)] for each value in attribute A.\n",
        "Here S is a set of instances, A is an attribute, and S_v is a subset of instances for a given value of v."
      ],
      "metadata": {
        "id": "p5UmI5fFlnwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv(\"/content/sample_data/car.data\", names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class'])\n",
        "\n",
        "# Encode categorical variables using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Split into features and target\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the Decision Tree model\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Testing the Decision Tree model\n",
        "predictions = dt_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtiLSgV48wSP",
        "outputId": "b29d13e1-5b53-49e5-facc-226a3c260c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Model quality analysis and comments:***\n",
        "\n",
        "The model demonstrates satisfactory performance on the test set with an accuracy of 97.40%. Further investigation of accuracy, recall, and feature importance may provide additional insight into its strengths and potential areas for improvement."
      ],
      "metadata": {
        "id": "VnLVAP30mNTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. General conclusions about the models:**\n",
        "\n",
        "**MLP:**\n",
        "\n",
        "Confusion Matrix:\n",
        "The model successfully classifies the classes '***unacc***' and '***good***' (with an accuracy of 76 and 14, respectively).\n",
        "Some shortcomings in the classification of the class '***acc***' (11 correctly classified out of 11) and '***vgood***' (14 correctly classified out of 17).\n",
        "\n",
        "***ROC-AUC:***\n",
        "\n",
        "The ROC-AUC value of 0.9984 indicates the high overall performance of the model in class discrimination.\n",
        "\n",
        "***Conclusion:*** The model exhibits high accuracy and efficiency in classifying cars according to specified characteristics.\n",
        "\n",
        "**Decision Tree:**\n",
        "\n",
        "The model based on the decision tree classifier shows commendable performance on the test set, achieving an accuracy of 97.40%. It effectively predicts vehicle acceptability by demonstrating its suitability for the task. Building a decision tree captures underlying patterns in the data set, providing a transparent model that can be interpreted. Potential ways for improvement could include tuning hyperparameters and exploring alternative tree-based models. Overall, the model demonstrates robustness and is a valuable tool for classifying vehicle acceptability."
      ],
      "metadata": {
        "id": "ZIOenXhDnJxj"
      }
    }
  ]
}